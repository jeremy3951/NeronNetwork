#include <math.h>
#include <stdint.h>

double sigmoid(double a){
    double o = ( 1 / (1+ exp(-a)));
    return o;
}

static uint64_t splitmix_x;
static inline uint64_t splitmix() {

    splitmix_x += 0x9E3779B97F4A7C15;
    uint64_t z = splitmix_x;
    z = (z ^ (z >> 30)) * 0xBF58476D1CE4E5B9;
    z = (z ^ (z >> 27)) * 0x94D049BB133111EB;
    return z ^ (z >> 31);
}

#define ANN_RAND() (((double) splitmix()) / UINT64_MAX)

void backward (double *in, double *res , double *gradient , int bias){

    gradient[3] += ( res[0] * (1-res[0]) ) * gradient[8-bias];
    gradient[3] += ( res[3] * (1-res[3]) ) * gradient[8-bias];

    gradient[2] += *(in+(0*3+2) ) * gradient[3] ; //in[0][2]
    gradient[2] += *(in+(1*3+2) ) * gradient[3] ; //in[1][2]

    gradient[1] += *(in+(0*3+1) ) * gradient[3] ; //in[0][1]
    gradient[1] += *(in+(1*3+1) ) * gradient[3] ; //in[1][1]

    gradient[0] += *(in+(0*3+0) ) * gradient[3] ; //in[0][0]
    gradient[0] += *(in+(1*3+2) ) * gradient[3] ; //in[1][0]

}

void backward2 (double *res , double *gradient ,double *ans){  //( process , gradient , output)

    double dx = 1.0 ;
    double oa =  res[2] - ans[0];
    double ob =  res[5] - ans[1];

    double *temp_grad = malloc( sizeof(double) * 2 * 3);

    /*
    令 output = b1 , b2  ans = ans1 , ans2

    loss function x = (b1-ans1)^2 + (b2-ans2)^2
                          oa            ob
    x = oa*oa + ob*ob
    dx = 1
    doa = 2*oa*dx
    dob = 2*ob*dx

    */
    temp_grad[0] = 2 * oa * dx ; // oa 的 梯度
    temp_grad[1] = 1*temp_grad[0];//db1
    temp_grad[2] = res[2] * (1- res[2]) *temp_grad[1]; //dq
    gradient[10] += temp_grad[2] ;


    temp_grad[3] = 2 * ob * dx ; // ob 的 梯度
    temp_grad[4] = temp_grad[3] *1;
    temp_grad[5] = res[5]*(1-res[5])*temp_grad[4] ;
    gradient[10] += temp_grad[5] ;

    /*case oa
    db1 = 1*doa
    b1 = s(q)
    dq = s*(1-s)*db1
    q = (c+w10)
    dw10 = dq
    dc = dq

      case ob
    db2 = 1*dob
    dans2 = 1*dob   不重要
    */

    gradient[9] += res[1] * gradient[10] ; //oa
    gradient[9] += res[4] * gradient[10] ; //ob

    gradient[8] += res[0] * gradient[10] ; //oa
    gradient[8] += res[3] * gradient[10] ; //ob

}


double test (double *in , int row , double *weight ){

    double *output = malloc(sizeof(double)*3) ;
    double *w = weight ;

    for(int i = 0 ; i <3;i++)
        output[i] = 0.0 ;

    for(int k = 0; k<2;k++){
           for(int j = 0;j<3;j++){
               output[k] += *w++ * *(in+(row*3)+j) ;
           }
           output[k] += *w++;
           output[k] = sigmoid(output[k]);
       }
                /*output layers*/
       for(int k = 0; k<2;k++){
           output[2] += *w++ * output[k];
       }
       output[2] += *w ;
       output[2] =sigmoid(output[2]); // 神經元的 output


    return output[2];
}


int main(){
   /* input */
   const double total_in[8][3] =
   {
        {0, 0, 0}, {0, 0, 1}, {0, 1, 0}, {0, 1, 1},
        {1, 0, 0}, {1, 0, 1}, {1, 1, 0}, {1, 1, 1},
    };
   double *ptr_to_in = total_in;

   const double total_output[8] = {
        0, 0, 1, 1, 0, 1, 0, 1,
    };
#define in_len sizeof(total_in)/sizeof(total_in[0])
#define out_len sizeof(total_out)/sizeof(total_out[0])

   double *ptr_to_ans = total_output;

   /* learning rate */
   double lr = 0.1 ;
   /* weight */
   double *w = malloc(sizeof(double)*12) ;
   double *temp_w = w;
   double *gradient = malloc(sizeof(double)*11) ;
   double *output = malloc(sizeof(double)*8);
   double *process = malloc(sizeof(double)*6);


   for(int i=0;i<12;i++){
        w[i]= ANN_RAND() -0.5;
        gradient[i] = 0.0;
   }


for(int times = 0; times <500 ; times ++){
   temp_w = w;

   for(int i=0;i<11;i++){
        gradient[i] = 0.0;
   }

   for(int s=0;s<2;s++){

        for(int i=3*s;i<(3*s+3);i++){
            process[i] = 0.0;
            //printf("%d\n" , i);
           }

        /*------------------------------forward--------------------------*/
           for(int k = 0; k<2;k++){       /*input-hidden*/
               for(int j = 0;j<3;j++){
                   process[k+3*s] += *temp_w++ * total_in[s][j] ;
               }
               process[k+3*s] += *temp_w++;
               process[k+3*s] = sigmoid(process[k]);
           }
           for(int k = 0; k<2;k++){       /*output layers*/
               process[2+3*s] += *temp_w++ * process[k];
           }
           process[2+3*s] += *temp_w ;
           process[2+3*s] =sigmoid(process[2+3*s]); // 神經元的 output
           output[s] = process[2+3*s];
        }

        /*------------------------------backward--------------------------*/
           backward2( process , gradient , ptr_to_ans);
           backward( ptr_to_in , process , gradient , 0) ;
           backward( ptr_to_in , process  , gradient+4 , 3) ;

        /*------------------------------update--------------------------*/
           for(int i=0;i<11;i++){
               w[i] -= lr * gradient[i];
           }


}
// predict
for(int i=0;i<2;i++){
    printf("%lf \n",test(ptr_to_in , i , w) );
}


   return 0;
}
