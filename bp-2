#include <math.h>
#include <stdint.h>

double sigmoid(double a){
    double o = ( 1 / (1+ exp(-a)));
    return o;
}

#include <stdint.h>
// 當輸入 x 大於等於 0 時，回傳 x，否則回傳 0
float ReLU(float x) {

    union {
        float f;
        int32_t i;
    } out = {.f = x}; /* 將資料存入 union */

    out.i &= ~(out.i >> 31);

    return out.f;
}

static uint64_t splitmix_x;
static inline uint64_t splitmix() {

    splitmix_x += 0x9E3779B97F4A7C15;
    uint64_t z = splitmix_x;
    z = (z ^ (z >> 30)) * 0xBF58476D1CE4E5B9;
    z = (z ^ (z >> 27)) * 0x94D049BB133111EB;
    return z ^ (z >> 31);
}

#define ANN_RAND() (((double) splitmix()) / UINT64_MAX)

void backward (double *w, double *in, double *res , double *gradient , int bias , int row){


    double dc1 = gradient[8] * gradient[10];
    double dc2 = gradient[9] * gradient[10];

    double df = ( res[0+bias] * (1-res[0+bias]) ) * dc1;
    double dg = ( res[1+bias] * (1-res[1+bias]) ) * dc2;

    for(int i =7;i>=0; i--){
        if(i>3){
            gradient[i] = dg;
            w[i] -= 0.5 * gradient[i];
            printf("w%d %lf \n",i , (w[i]) );

        }else{
            gradient[i] = df;
            w[i] -= 0.5 * gradient[i];
            printf("w%d %lf \n",i , (w[i]) );
        }
    }
    printf("-------------\n");

}

void backward2 (double *w, double *in, double *res , double *gradient ,double *ans){  //( process , gradient , output)


    double o1234567[8] ;
    for(int i =0;i<8;i++){
        o1234567[i] = res[3*i+2] - ans[i] ;
        printf("res%d %lf - ", i,(res[3*i+2]) );
        printf("ans%d %lf \n", i,(ans[i]) );
    }

    double grad_d[8];
    for(int i =0;i<8;i++){
        grad_d[i] = res[3*i+2] * ( 1 - res[3*i+2] ) * o1234567[i]  ;

        gradient[10] = 1 * grad_d[i] ;
        w[10] -= 0.5 * gradient[10];
        printf("w10 %lf \n",(w[10]) );

        gradient[9]  = res[3*i+1] * grad_d[i] ;
        w[9] -= 0.5 * gradient[9];
        printf("w9 %lf \n",(w[9]) );

        gradient[8]  = res[3*i] * grad_d[i];
        w[8] -= 0.5 * gradient[8];
        printf("w8 %lf \n",(w[8]) );

        backward(w , in , res , gradient , 3*i , i );
    }

}


double test (double *in , int row , double *weight ){

    double *output = malloc(sizeof(double)*3) ;
    double *w = weight ;

    for(int i = 0 ; i <3;i++)
        output[i] = 0.0 ;

    for(int k = 0; k<2;k++){
           for(int j = 0;j<3;j++){
               output[k] += *w++ * *(in+(row*3)+j) ;
           }
           output[k] += *w++;
           output[k] = sigmoid(output[k]);
       }
                /*output layers*/
       for(int k = 0; k<2;k++){
           output[2] += *w++ * output[k];
       }
       output[2] += *w ;
       output[2] =sigmoid(output[2]); // 神經元的 output


    return output[2];
}


int main(){
   /* input */
   const double total_in[8][3] =
   {
        {0, 0, 0}, {0, 0, 1}, {0, 1, 0}, {0, 1, 1},
        {1, 0, 0}, {1, 0, 1}, {1, 1, 0}, {1, 1, 1},
    };
   double *ptr_to_in = total_in;

   const double total_output[8] = {
        0, 0, 1, 1, 0, 1, 0, 1,
    };
#define in_len sizeof(total_in)/sizeof(total_in[0])
#define out_len sizeof(total_out)/sizeof(total_out[0])

   double *ptr_to_ans = total_output;

   /* learning rate */
   double lr = 1 ;
   /* weight */
   double *w = malloc(sizeof(double)*11) ;
   double *temp_w = w;
   double *gradient = malloc(sizeof(double)*11) ;


   double *output = malloc(sizeof(double)*8);
   double *process = malloc(sizeof(double)* 8 *3);


   for(int i=0;i<11;i++){
        w[i]= ANN_RAND() -0.5;
        gradient[i] = 0.0;
   }


for(int times = 0; times <1; times ++){

   for(int i=0;i<11;i++){
        gradient[i] = 0.0;
   }

   for(int s=0;s<8;s++){
        temp_w = w;
        for(int i=3*s;i<(3*s+3);i++){
            process[i] = 0.0;
           }

        /*------------------------------forward--------------------------*/
           for(int k = 0; k<2;k++){       /*input-hidden*/
               for(int j = 0;j<3;j++){
                   process[k+3*s] += *temp_w++ * total_in[s][j] ;
               }

               process[k+3*s] += *temp_w++;
               //process[k+3*s] = (double)ReLU((float) process[k+3*s]);
               process[k+3*s] = sigmoid(process[k+3*s]);
           }
           for(int k = 0; k<2;k++){       /*output layers*/
               process[2+3*s] += *temp_w++ * process[k+3*s];
           }
           process[2+3*s] += *temp_w ;
           //process[2+3*s] = (double)ReLU((float) process[2+3*s]);
           process[2+3*s] =sigmoid(process[2+3*s]); // 神經元的 output
           output[s] = process[2+3*s];
        }


        /*------------------------------backward--------------------------*/
           backward2(w, ptr_to_in , process , gradient , ptr_to_ans);

        /*------------------------------update--------------------------*/
           for(int i=0;i<11;i++){
               //w[i] -= lr * gradient[i];
           }
           printf("----------------Round%d--------------\n" , times+1);
           for(int h=0;h<11;h++){
            //printf("w %d %lf \n",h , (w[h]) );

        }



}
// predict
for(int i=0;i<8;i++){
    printf("%lf \n",test(ptr_to_in , i , w) );
}


   return 0;
}
